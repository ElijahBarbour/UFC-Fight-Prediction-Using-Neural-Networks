{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"Tensorflow version: {tf.version.VERSION}\")\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Input\n",
    "from tensorflow.keras import optimizers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_fighter</th>\n",
       "      <th>B_fighter</th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>finish_details</th>\n",
       "      <th>finish_round</th>\n",
       "      <th>finish_round_time</th>\n",
       "      <th>total_fight_time_secs</th>\n",
       "      <th>r_dec_odds</th>\n",
       "      <th>b_dec_odds</th>\n",
       "      <th>r_sub_odds</th>\n",
       "      <th>b_sub_odds</th>\n",
       "      <th>r_ko_odds</th>\n",
       "      <th>b_ko_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uriah Hall</td>\n",
       "      <td>Sean Strickland</td>\n",
       "      <td>175</td>\n",
       "      <td>-210</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheyanne Buys</td>\n",
       "      <td>Gloria de Paula</td>\n",
       "      <td>-145</td>\n",
       "      <td>125</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Red</td>\n",
       "      <td>...</td>\n",
       "      <td>Kick</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niklas Stolze</td>\n",
       "      <td>Jared Gooden</td>\n",
       "      <td>-180</td>\n",
       "      <td>155</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>Punch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1:08</td>\n",
       "      <td>68.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collin Anglin</td>\n",
       "      <td>Melsik Baghdasaryan</td>\n",
       "      <td>135</td>\n",
       "      <td>-155</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>64.516129</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>Kick</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1:50</td>\n",
       "      <td>410.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bryan Barberena</td>\n",
       "      <td>Jason Witt</td>\n",
       "      <td>-265</td>\n",
       "      <td>215</td>\n",
       "      <td>37.735849</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>900.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>850.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         R_fighter            B_fighter  R_odds  B_odds        R_ev  \\\n",
       "0       Uriah Hall      Sean Strickland     175    -210  175.000000   \n",
       "1    Cheyanne Buys      Gloria de Paula    -145     125   68.965517   \n",
       "2    Niklas Stolze         Jared Gooden    -180     155   55.555556   \n",
       "3    Collin Anglin  Melsik Baghdasaryan     135    -155  135.000000   \n",
       "4  Bryan Barberena           Jason Witt    -265     215   37.735849   \n",
       "\n",
       "         B_ev        date                location country Winner  ...  \\\n",
       "0   47.619048  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "1  125.000000  2021-07-31  Las Vegas, Nevada, USA     USA    Red  ...   \n",
       "2  155.000000  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "3   64.516129  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "4  215.000000  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "\n",
       "   finish_details finish_round finish_round_time  total_fight_time_secs  \\\n",
       "0             NaN          5.0              5:00                 1500.0   \n",
       "1            Kick          1.0              1:00                   60.0   \n",
       "2           Punch          1.0              1:08                   68.0   \n",
       "3            Kick          2.0              1:50                  410.0   \n",
       "4             NaN          3.0              5:00                  900.0   \n",
       "\n",
       "   r_dec_odds  b_dec_odds  r_sub_odds  b_sub_odds  r_ko_odds  b_ko_odds  \n",
       "0       650.0       225.0      2500.0       800.0      275.0      165.0  \n",
       "1       100.0       200.0       800.0      1400.0      900.0      900.0  \n",
       "2       180.0       300.0       600.0      1200.0      300.0      600.0  \n",
       "3       240.0       250.0      1000.0       850.0      650.0      225.0  \n",
       "4       300.0       500.0       550.0       750.0      120.0      850.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UFC_Data = pd.read_csv('./ufc-master.csv')\n",
    "UFC_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_fighter</th>\n",
       "      <th>B_fighter</th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>finish_round</th>\n",
       "      <th>finish_round_time</th>\n",
       "      <th>total_fight_time_secs</th>\n",
       "      <th>r_dec_odds</th>\n",
       "      <th>b_dec_odds</th>\n",
       "      <th>r_sub_odds</th>\n",
       "      <th>b_sub_odds</th>\n",
       "      <th>r_ko_odds</th>\n",
       "      <th>b_ko_odds</th>\n",
       "      <th>Winner_Categorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uriah Hall</td>\n",
       "      <td>Sean Strickland</td>\n",
       "      <td>175</td>\n",
       "      <td>-210</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheyanne Buys</td>\n",
       "      <td>Gloria de Paula</td>\n",
       "      <td>-145</td>\n",
       "      <td>125</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Red</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niklas Stolze</td>\n",
       "      <td>Jared Gooden</td>\n",
       "      <td>-180</td>\n",
       "      <td>155</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1:08</td>\n",
       "      <td>68.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collin Anglin</td>\n",
       "      <td>Melsik Baghdasaryan</td>\n",
       "      <td>135</td>\n",
       "      <td>-155</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>64.516129</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1:50</td>\n",
       "      <td>410.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bryan Barberena</td>\n",
       "      <td>Jason Witt</td>\n",
       "      <td>-265</td>\n",
       "      <td>215</td>\n",
       "      <td>37.735849</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>900.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         R_fighter            B_fighter  R_odds  B_odds        R_ev  \\\n",
       "0       Uriah Hall      Sean Strickland     175    -210  175.000000   \n",
       "1    Cheyanne Buys      Gloria de Paula    -145     125   68.965517   \n",
       "2    Niklas Stolze         Jared Gooden    -180     155   55.555556   \n",
       "3    Collin Anglin  Melsik Baghdasaryan     135    -155  135.000000   \n",
       "4  Bryan Barberena           Jason Witt    -265     215   37.735849   \n",
       "\n",
       "         B_ev        date                location country Winner  ...  \\\n",
       "0   47.619048  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "1  125.000000  2021-07-31  Las Vegas, Nevada, USA     USA    Red  ...   \n",
       "2  155.000000  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "3   64.516129  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "4  215.000000  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "\n",
       "   finish_round finish_round_time total_fight_time_secs  r_dec_odds  \\\n",
       "0           5.0              5:00                1500.0       650.0   \n",
       "1           1.0              1:00                  60.0       100.0   \n",
       "2           1.0              1:08                  68.0       180.0   \n",
       "3           2.0              1:50                 410.0       240.0   \n",
       "4           3.0              5:00                 900.0       300.0   \n",
       "\n",
       "   b_dec_odds  r_sub_odds  b_sub_odds  r_ko_odds  b_ko_odds  \\\n",
       "0       225.0      2500.0       800.0      275.0      165.0   \n",
       "1       200.0       800.0      1400.0      900.0      900.0   \n",
       "2       300.0       600.0      1200.0      300.0      600.0   \n",
       "3       250.0      1000.0       850.0      650.0      225.0   \n",
       "4       500.0       550.0       750.0      120.0      850.0   \n",
       "\n",
       "   Winner_Categorized  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Where did i get this? from first project\n",
    "def Categorize_Winner(df):\n",
    "    df['Winner_Categorized'] = df['Winner'].astype('category')\n",
    "\n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return df\n",
    "\n",
    "UFC_Data = Categorize_Winner(UFC_Data)\n",
    "UFC_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_fighter</th>\n",
       "      <th>B_fighter</th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>height_dif</th>\n",
       "      <th>reach_dif</th>\n",
       "      <th>age_dif</th>\n",
       "      <th>sig_str_dif</th>\n",
       "      <th>avg_sub_att_dif</th>\n",
       "      <th>avg_td_dif</th>\n",
       "      <th>empty_arena</th>\n",
       "      <th>constant_1</th>\n",
       "      <th>better_rank</th>\n",
       "      <th>Winner_Categorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uriah Hall</td>\n",
       "      <td>Sean Strickland</td>\n",
       "      <td>175</td>\n",
       "      <td>-210</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>-7</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheyanne Buys</td>\n",
       "      <td>Gloria de Paula</td>\n",
       "      <td>-145</td>\n",
       "      <td>125</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Red</td>\n",
       "      <td>...</td>\n",
       "      <td>5.08</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neither</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niklas Stolze</td>\n",
       "      <td>Jared Gooden</td>\n",
       "      <td>-180</td>\n",
       "      <td>155</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collin Anglin</td>\n",
       "      <td>Melsik Baghdasaryan</td>\n",
       "      <td>135</td>\n",
       "      <td>-155</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>64.516129</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bryan Barberena</td>\n",
       "      <td>Jason Witt</td>\n",
       "      <td>-265</td>\n",
       "      <td>215</td>\n",
       "      <td>37.735849</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         R_fighter            B_fighter  R_odds  B_odds        R_ev  \\\n",
       "0       Uriah Hall      Sean Strickland     175    -210  175.000000   \n",
       "1    Cheyanne Buys      Gloria de Paula    -145     125   68.965517   \n",
       "2    Niklas Stolze         Jared Gooden    -180     155   55.555556   \n",
       "3    Collin Anglin  Melsik Baghdasaryan     135    -155  135.000000   \n",
       "4  Bryan Barberena           Jason Witt    -265     215   37.735849   \n",
       "\n",
       "         B_ev        date                location country Winner  ...  \\\n",
       "0   47.619048  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "1  125.000000  2021-07-31  Las Vegas, Nevada, USA     USA    Red  ...   \n",
       "2  155.000000  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "3   64.516129  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "4  215.000000  2021-07-31  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "\n",
       "   height_dif reach_dif age_dif  sig_str_dif  avg_sub_att_dif  avg_td_dif  \\\n",
       "0        2.54     -7.62      -7         1.98              0.1        0.74   \n",
       "1        5.08     10.16       0        -0.93              1.0       -0.48   \n",
       "2        0.00      5.08      -1         2.75              0.0        0.03   \n",
       "3        0.00     -2.54       1         1.51              0.0       -2.75   \n",
       "4       -5.08     -5.08       2        -2.63              0.9        6.25   \n",
       "\n",
       "   empty_arena  constant_1  better_rank  Winner_Categorized  \n",
       "0            1           1          Red                   0  \n",
       "1            1           1      neither                   1  \n",
       "2            1           1      neither                   0  \n",
       "3            1           1      neither                   0  \n",
       "4            1           1      neither                   0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UFC_Data.isnull().sum()\n",
    "df = pd.DataFrame(UFC_Data.dropna(axis='columns'))\n",
    "df = pd.DataFrame(df.dropna())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_longest_win_streak</th>\n",
       "      <th>B_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_dif</th>\n",
       "      <th>height_dif</th>\n",
       "      <th>reach_dif</th>\n",
       "      <th>age_dif</th>\n",
       "      <th>sig_str_dif</th>\n",
       "      <th>avg_sub_att_dif</th>\n",
       "      <th>avg_td_dif</th>\n",
       "      <th>empty_arena</th>\n",
       "      <th>constant_1</th>\n",
       "      <th>Winner_Categorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175</td>\n",
       "      <td>-210</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>-7</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-145</td>\n",
       "      <td>125</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-180</td>\n",
       "      <td>155</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td>-155</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>64.516129</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-265</td>\n",
       "      <td>215</td>\n",
       "      <td>37.735849</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_odds  B_odds        R_ev        B_ev  no_of_rounds  \\\n",
       "0     175    -210  175.000000   47.619048             5   \n",
       "1    -145     125   68.965517  125.000000             3   \n",
       "2    -180     155   55.555556  155.000000             3   \n",
       "3     135    -155  135.000000   64.516129             3   \n",
       "4    -265     215   37.735849  215.000000             3   \n",
       "\n",
       "   B_current_lose_streak  B_current_win_streak  B_draw  B_longest_win_streak  \\\n",
       "0                      0                     4       0                     4   \n",
       "1                      1                     0       0                     1   \n",
       "2                      2                     0       0                     0   \n",
       "3                      0                     1       0                     1   \n",
       "4                      1                     0       0                     1   \n",
       "\n",
       "   B_losses  ...  sub_dif  height_dif  reach_dif  age_dif  sig_str_dif  \\\n",
       "0         3  ...        1        2.54      -7.62       -7         1.98   \n",
       "1         1  ...        0        5.08      10.16        0        -0.93   \n",
       "2         2  ...        0        0.00       5.08       -1         2.75   \n",
       "3         0  ...        0        0.00      -2.54        1         1.51   \n",
       "4         2  ...        0       -5.08      -5.08        2        -2.63   \n",
       "\n",
       "   avg_sub_att_dif  avg_td_dif  empty_arena  constant_1  Winner_Categorized  \n",
       "0              0.1        0.74            1           1                   0  \n",
       "1              1.0       -0.48            1           1                   1  \n",
       "2              0.0        0.03            1           1                   0  \n",
       "3              0.0       -2.75            1           1                   0  \n",
       "4              0.9        6.25            1           1                   0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Where did i get this? From first project.\n",
    "non_num = []\n",
    "for col in df:\n",
    "    if df[col].dtypes != \"float64\" and df[col].dtypes != \"int64\":\n",
    "        non_num.append(col)\n",
    "non_num.remove(\"Winner_Categorized\")\n",
    "df = pd.DataFrame(df.drop(columns = non_num))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_odds                          0\n",
      "B_odds                          0\n",
      "R_ev                            0\n",
      "B_ev                            0\n",
      "no_of_rounds                    0\n",
      "B_current_lose_streak           0\n",
      "B_current_win_streak            0\n",
      "B_draw                          0\n",
      "B_longest_win_streak            0\n",
      "B_losses                        0\n",
      "B_total_rounds_fought           0\n",
      "B_total_title_bouts             0\n",
      "B_win_by_Decision_Majority      0\n",
      "B_win_by_Decision_Split         0\n",
      "B_win_by_Decision_Unanimous     0\n",
      "B_win_by_KO/TKO                 0\n",
      "B_win_by_Submission             0\n",
      "B_win_by_TKO_Doctor_Stoppage    0\n",
      "B_wins                          0\n",
      "B_Height_cms                    0\n",
      "B_Reach_cms                     0\n",
      "B_Weight_lbs                    0\n",
      "R_current_lose_streak           0\n",
      "R_current_win_streak            0\n",
      "R_draw                          0\n",
      "R_longest_win_streak            0\n",
      "R_losses                        0\n",
      "R_total_rounds_fought           0\n",
      "R_total_title_bouts             0\n",
      "R_win_by_Decision_Majority      0\n",
      "R_win_by_Decision_Split         0\n",
      "R_win_by_Decision_Unanimous     0\n",
      "R_win_by_KO/TKO                 0\n",
      "R_win_by_Submission             0\n",
      "R_win_by_TKO_Doctor_Stoppage    0\n",
      "R_wins                          0\n",
      "R_Height_cms                    0\n",
      "R_Reach_cms                     0\n",
      "R_Weight_lbs                    0\n",
      "R_age                           0\n",
      "B_age                           0\n",
      "lose_streak_dif                 0\n",
      "win_streak_dif                  0\n",
      "longest_win_streak_dif          0\n",
      "win_dif                         0\n",
      "loss_dif                        0\n",
      "total_round_dif                 0\n",
      "total_title_bout_dif            0\n",
      "ko_dif                          0\n",
      "sub_dif                         0\n",
      "height_dif                      0\n",
      "reach_dif                       0\n",
      "age_dif                         0\n",
      "sig_str_dif                     0\n",
      "avg_sub_att_dif                 0\n",
      "avg_td_dif                      0\n",
      "empty_arena                     0\n",
      "constant_1                      0\n",
      "Winner_Categorized              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum(axis='rows'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_odds                          0\n",
      "B_odds                          0\n",
      "R_ev                            0\n",
      "B_ev                            0\n",
      "no_of_rounds                    0\n",
      "B_current_lose_streak           0\n",
      "B_current_win_streak            0\n",
      "B_draw                          0\n",
      "B_longest_win_streak            0\n",
      "B_losses                        0\n",
      "B_total_rounds_fought           0\n",
      "B_total_title_bouts             0\n",
      "B_win_by_Decision_Majority      0\n",
      "B_win_by_Decision_Split         0\n",
      "B_win_by_Decision_Unanimous     0\n",
      "B_win_by_KO/TKO                 0\n",
      "B_win_by_Submission             0\n",
      "B_win_by_TKO_Doctor_Stoppage    0\n",
      "B_wins                          0\n",
      "B_Height_cms                    0\n",
      "B_Reach_cms                     0\n",
      "B_Weight_lbs                    0\n",
      "R_current_lose_streak           0\n",
      "R_current_win_streak            0\n",
      "R_draw                          0\n",
      "R_longest_win_streak            0\n",
      "R_losses                        0\n",
      "R_total_rounds_fought           0\n",
      "R_total_title_bouts             0\n",
      "R_win_by_Decision_Majority      0\n",
      "R_win_by_Decision_Split         0\n",
      "R_win_by_Decision_Unanimous     0\n",
      "R_win_by_KO/TKO                 0\n",
      "R_win_by_Submission             0\n",
      "R_win_by_TKO_Doctor_Stoppage    0\n",
      "R_wins                          0\n",
      "R_Height_cms                    0\n",
      "R_Reach_cms                     0\n",
      "R_Weight_lbs                    0\n",
      "R_age                           0\n",
      "B_age                           0\n",
      "lose_streak_dif                 0\n",
      "win_streak_dif                  0\n",
      "longest_win_streak_dif          0\n",
      "win_dif                         0\n",
      "loss_dif                        0\n",
      "total_round_dif                 0\n",
      "total_title_bout_dif            0\n",
      "ko_dif                          0\n",
      "sub_dif                         0\n",
      "height_dif                      0\n",
      "reach_dif                       0\n",
      "age_dif                         0\n",
      "sig_str_dif                     0\n",
      "avg_sub_att_dif                 0\n",
      "avg_td_dif                      0\n",
      "empty_arena                     0\n",
      "constant_1                      0\n",
      "Winner_Categorized              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum(axis='rows'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It contains 0 infinite values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_longest_win_streak</th>\n",
       "      <th>B_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_dif</th>\n",
       "      <th>height_dif</th>\n",
       "      <th>reach_dif</th>\n",
       "      <th>age_dif</th>\n",
       "      <th>sig_str_dif</th>\n",
       "      <th>avg_sub_att_dif</th>\n",
       "      <th>avg_td_dif</th>\n",
       "      <th>empty_arena</th>\n",
       "      <th>constant_1</th>\n",
       "      <th>Winner_Categorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175</td>\n",
       "      <td>-210</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>-7</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-145</td>\n",
       "      <td>125</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-180</td>\n",
       "      <td>155</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td>-155</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>64.516129</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-265</td>\n",
       "      <td>215</td>\n",
       "      <td>37.735849</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_odds  B_odds        R_ev        B_ev  no_of_rounds  \\\n",
       "0     175    -210  175.000000   47.619048             5   \n",
       "1    -145     125   68.965517  125.000000             3   \n",
       "2    -180     155   55.555556  155.000000             3   \n",
       "3     135    -155  135.000000   64.516129             3   \n",
       "4    -265     215   37.735849  215.000000             3   \n",
       "\n",
       "   B_current_lose_streak  B_current_win_streak  B_draw  B_longest_win_streak  \\\n",
       "0                      0                     4       0                     4   \n",
       "1                      1                     0       0                     1   \n",
       "2                      2                     0       0                     0   \n",
       "3                      0                     1       0                     1   \n",
       "4                      1                     0       0                     1   \n",
       "\n",
       "   B_losses  ...  sub_dif  height_dif  reach_dif  age_dif  sig_str_dif  \\\n",
       "0         3  ...        1        2.54      -7.62       -7         1.98   \n",
       "1         1  ...        0        5.08      10.16        0        -0.93   \n",
       "2         2  ...        0        0.00       5.08       -1         2.75   \n",
       "3         0  ...        0        0.00      -2.54        1         1.51   \n",
       "4         2  ...        0       -5.08      -5.08        2        -2.63   \n",
       "\n",
       "   avg_sub_att_dif  avg_td_dif  empty_arena  constant_1  Winner_Categorized  \n",
       "0              0.1        0.74            1           1                   0  \n",
       "1              1.0       -0.48            1           1                   1  \n",
       "2              0.0        0.03            1           1                   0  \n",
       "3              0.0       -2.75            1           1                   0  \n",
       "4              0.9        6.25            1           1                   0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.isinf(df).values.sum()\n",
    "print(\"It contains \" + str(count) + \" infinite values\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape:  (3369, 59)\n",
      "Validation Dataset Shape:  (722, 59)\n",
      "Test Dataset Shape:  (722, 59)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size = 0.3)\n",
    "test_df, validation_df = train_test_split(test_df, test_size = 0.5)\n",
    "print(\"Training Dataset Shape: \", train_df.shape)\n",
    "print(\"Validation Dataset Shape: \", validation_df.shape)\n",
    "print(\"Test Dataset Shape: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R_odds</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-119.505491</td>\n",
       "      <td>268.919514</td>\n",
       "      <td>-1667.000000</td>\n",
       "      <td>-255.000000</td>\n",
       "      <td>-150.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_odds</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>67.040368</td>\n",
       "      <td>248.071467</td>\n",
       "      <td>-1200.000000</td>\n",
       "      <td>-145.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ev</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>94.486630</td>\n",
       "      <td>82.871584</td>\n",
       "      <td>5.998800</td>\n",
       "      <td>39.215686</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_ev</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>167.715926</td>\n",
       "      <td>137.373806</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_rounds</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>3.195904</td>\n",
       "      <td>0.591082</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.478183</td>\n",
       "      <td>0.773416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.893143</td>\n",
       "      <td>1.338443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_draw</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_longest_win_streak</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.796379</td>\n",
       "      <td>1.935902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_losses</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.724547</td>\n",
       "      <td>2.101237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_total_rounds_fought</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>10.831404</td>\n",
       "      <td>13.310675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_total_title_bouts</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.238053</td>\n",
       "      <td>1.084478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_win_by_Decision_Majority</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.113550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_win_by_Decision_Split</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.254675</td>\n",
       "      <td>0.557152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_win_by_Decision_Unanimous</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.003562</td>\n",
       "      <td>1.543506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_win_by_KO/TKO</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.974473</td>\n",
       "      <td>1.709256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_win_by_Submission</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.580291</td>\n",
       "      <td>1.198838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_win_by_TKO_Doctor_Stoppage</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>0.185911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_wins</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>2.922529</td>\n",
       "      <td>3.681854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_Height_cms</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>178.169213</td>\n",
       "      <td>8.926344</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>172.720000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>185.420000</td>\n",
       "      <td>210.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_Reach_cms</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>182.503476</td>\n",
       "      <td>11.099164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.260000</td>\n",
       "      <td>182.880000</td>\n",
       "      <td>190.500000</td>\n",
       "      <td>213.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_Weight_lbs</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>165.266251</td>\n",
       "      <td>34.607548</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_current_lose_streak</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.607599</td>\n",
       "      <td>0.858665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_current_win_streak</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.092906</td>\n",
       "      <td>1.781063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_draw</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.013951</td>\n",
       "      <td>0.127026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_longest_win_streak</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>2.587415</td>\n",
       "      <td>2.263289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_losses</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>2.391214</td>\n",
       "      <td>2.501922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_total_rounds_fought</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>16.136836</td>\n",
       "      <td>17.370610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_total_title_bouts</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.571980</td>\n",
       "      <td>1.557565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_win_by_Decision_Majority</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>0.157837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_win_by_Decision_Split</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.371030</td>\n",
       "      <td>0.666961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_win_by_Decision_Unanimous</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.482636</td>\n",
       "      <td>1.830174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_win_by_KO/TKO</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.466904</td>\n",
       "      <td>2.085506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_win_by_Submission</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>1.560993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_win_by_TKO_Doctor_Stoppage</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.048679</td>\n",
       "      <td>0.231191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_wins</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>4.373405</td>\n",
       "      <td>4.354069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_Height_cms</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>178.131855</td>\n",
       "      <td>8.973517</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>172.720000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>185.420000</td>\n",
       "      <td>210.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>182.774019</td>\n",
       "      <td>10.848254</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>175.260000</td>\n",
       "      <td>182.880000</td>\n",
       "      <td>190.500000</td>\n",
       "      <td>214.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>165.751558</td>\n",
       "      <td>34.772475</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_age</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>30.098249</td>\n",
       "      <td>4.097696</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_age</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>29.564559</td>\n",
       "      <td>4.002011</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lose_streak_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.113980</td>\n",
       "      <td>1.003887</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_streak_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.199466</td>\n",
       "      <td>1.810660</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest_win_streak_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.791036</td>\n",
       "      <td>2.115356</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-1.450876</td>\n",
       "      <td>4.147378</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.388246</td>\n",
       "      <td>2.917521</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_round_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-5.305432</td>\n",
       "      <td>17.808918</td>\n",
       "      <td>-448.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_title_bout_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.333927</td>\n",
       "      <td>1.747524</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ko_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.508459</td>\n",
       "      <td>2.110657</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.314633</td>\n",
       "      <td>1.808571</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.013695</td>\n",
       "      <td>7.175212</td>\n",
       "      <td>-187.960000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>30.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reach_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.368341</td>\n",
       "      <td>9.827409</td>\n",
       "      <td>-187.960000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>30.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.360938</td>\n",
       "      <td>5.155455</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_str_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-3.561826</td>\n",
       "      <td>22.612190</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>-14.400000</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>128.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_sub_att_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.070874</td>\n",
       "      <td>0.833851</td>\n",
       "      <td>-6.400000</td>\n",
       "      <td>-0.442857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_td_dif</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>-0.208888</td>\n",
       "      <td>1.671090</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>10.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empty_arena</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.130899</td>\n",
       "      <td>0.337340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constant_1</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winner_Categorized</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.590086</td>\n",
       "      <td>0.491891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count        mean         std          min  \\\n",
       "R_odds                        3369.0 -119.505491  268.919514 -1667.000000   \n",
       "B_odds                        3369.0   67.040368  248.071467 -1200.000000   \n",
       "R_ev                          3369.0   94.486630   82.871584     5.998800   \n",
       "B_ev                          3369.0  167.715926  137.373806     8.333333   \n",
       "no_of_rounds                  3369.0    3.195904    0.591082     3.000000   \n",
       "B_current_lose_streak         3369.0    0.478183    0.773416     0.000000   \n",
       "B_current_win_streak          3369.0    0.893143    1.338443     0.000000   \n",
       "B_draw                        3369.0    0.010092    0.108511     0.000000   \n",
       "B_longest_win_streak          3369.0    1.796379    1.935902     0.000000   \n",
       "B_losses                      3369.0    1.724547    2.101237     0.000000   \n",
       "B_total_rounds_fought         3369.0   10.831404   13.310675     0.000000   \n",
       "B_total_title_bouts           3369.0    0.238053    1.084478     0.000000   \n",
       "B_win_by_Decision_Majority    3369.0    0.013060    0.113550     0.000000   \n",
       "B_win_by_Decision_Split       3369.0    0.254675    0.557152     0.000000   \n",
       "B_win_by_Decision_Unanimous   3369.0    1.003562    1.543506     0.000000   \n",
       "B_win_by_KO/TKO               3369.0    0.974473    1.709256     0.000000   \n",
       "B_win_by_Submission           3369.0    0.580291    1.198838     0.000000   \n",
       "B_win_by_TKO_Doctor_Stoppage  3369.0    0.032651    0.185911     0.000000   \n",
       "B_wins                        3369.0    2.922529    3.681854     0.000000   \n",
       "B_Height_cms                  3369.0  178.169213    8.926344   152.400000   \n",
       "B_Reach_cms                   3369.0  182.503476   11.099164     0.000000   \n",
       "B_Weight_lbs                  3369.0  165.266251   34.607548   115.000000   \n",
       "R_current_lose_streak         3369.0    0.607599    0.858665     0.000000   \n",
       "R_current_win_streak          3369.0    1.092906    1.781063     0.000000   \n",
       "R_draw                        3369.0    0.013951    0.127026     0.000000   \n",
       "R_longest_win_streak          3369.0    2.587415    2.263289     0.000000   \n",
       "R_losses                      3369.0    2.391214    2.501922     0.000000   \n",
       "R_total_rounds_fought         3369.0   16.136836   17.370610     0.000000   \n",
       "R_total_title_bouts           3369.0    0.571980    1.557565     0.000000   \n",
       "R_win_by_Decision_Majority    3369.0    0.024933    0.157837     0.000000   \n",
       "R_win_by_Decision_Split       3369.0    0.371030    0.666961     0.000000   \n",
       "R_win_by_Decision_Unanimous   3369.0    1.482636    1.830174     0.000000   \n",
       "R_win_by_KO/TKO               3369.0    1.466904    2.085506     0.000000   \n",
       "R_win_by_Submission           3369.0    0.894924    1.560993     0.000000   \n",
       "R_win_by_TKO_Doctor_Stoppage  3369.0    0.048679    0.231191     0.000000   \n",
       "R_wins                        3369.0    4.373405    4.354069     0.000000   \n",
       "R_Height_cms                  3369.0  178.131855    8.973517   152.400000   \n",
       "R_Reach_cms                   3369.0  182.774019   10.848254   152.400000   \n",
       "R_Weight_lbs                  3369.0  165.751558   34.772475   115.000000   \n",
       "R_age                         3369.0   30.098249    4.097696    19.000000   \n",
       "B_age                         3369.0   29.564559    4.002011    19.000000   \n",
       "lose_streak_dif               3369.0    0.113980    1.003887    -5.000000   \n",
       "win_streak_dif                3369.0   -0.199466    1.810660   -13.000000   \n",
       "longest_win_streak_dif        3369.0   -0.791036    2.115356   -12.000000   \n",
       "win_dif                       3369.0   -1.450876    4.147378   -27.000000   \n",
       "loss_dif                      3369.0    0.388246    2.917521   -18.000000   \n",
       "total_round_dif               3369.0   -5.305432   17.808918  -448.000000   \n",
       "total_title_bout_dif          3369.0   -0.333927    1.747524   -16.000000   \n",
       "ko_dif                        3369.0   -0.508459    2.110657   -17.000000   \n",
       "sub_dif                       3369.0   -0.314633    1.808571   -13.000000   \n",
       "height_dif                    3369.0   -0.013695    7.175212  -187.960000   \n",
       "reach_dif                     3369.0   -0.368341    9.827409  -187.960000   \n",
       "age_dif                       3369.0    0.360938    5.155455   -17.000000   \n",
       "sig_str_dif                   3369.0   -3.561826   22.612190  -113.000000   \n",
       "avg_sub_att_dif               3369.0   -0.070874    0.833851    -6.400000   \n",
       "avg_td_dif                    3369.0   -0.208888    1.671090   -11.000000   \n",
       "empty_arena                   3369.0    0.130899    0.337340     0.000000   \n",
       "constant_1                    3369.0    1.000000    0.000000     1.000000   \n",
       "Winner_Categorized            3369.0    0.590086    0.491891     0.000000   \n",
       "\n",
       "                                     25%         50%         75%          max  \n",
       "R_odds                       -255.000000 -150.000000  125.000000   775.000000  \n",
       "B_odds                       -145.000000  130.000000  220.000000  1300.000000  \n",
       "R_ev                           39.215686   66.666667  125.000000   775.000000  \n",
       "B_ev                           68.965517  130.000000  220.000000  1300.000000  \n",
       "no_of_rounds                    3.000000    3.000000    3.000000     5.000000  \n",
       "B_current_lose_streak           0.000000    0.000000    1.000000     6.000000  \n",
       "B_current_win_streak            0.000000    0.000000    1.000000    12.000000  \n",
       "B_draw                          0.000000    0.000000    0.000000     2.000000  \n",
       "B_longest_win_streak            0.000000    1.000000    3.000000    17.000000  \n",
       "B_losses                        0.000000    1.000000    3.000000    15.000000  \n",
       "B_total_rounds_fought           1.000000    6.000000   15.000000    97.000000  \n",
       "B_total_title_bouts             0.000000    0.000000    0.000000    16.000000  \n",
       "B_win_by_Decision_Majority      0.000000    0.000000    0.000000     1.000000  \n",
       "B_win_by_Decision_Split         0.000000    0.000000    0.000000     4.000000  \n",
       "B_win_by_Decision_Unanimous     0.000000    0.000000    1.000000    10.000000  \n",
       "B_win_by_KO/TKO                 0.000000    0.000000    1.000000    20.000000  \n",
       "B_win_by_Submission             0.000000    0.000000    1.000000    13.000000  \n",
       "B_win_by_TKO_Doctor_Stoppage    0.000000    0.000000    0.000000     2.000000  \n",
       "B_wins                          0.000000    2.000000    4.000000    31.000000  \n",
       "B_Height_cms                  172.720000  177.800000  185.420000   210.820000  \n",
       "B_Reach_cms                   175.260000  182.880000  190.500000   213.360000  \n",
       "B_Weight_lbs                  135.000000  155.000000  185.000000   265.000000  \n",
       "R_current_lose_streak           0.000000    0.000000    1.000000     6.000000  \n",
       "R_current_win_streak            0.000000    0.000000    1.000000    16.000000  \n",
       "R_draw                          0.000000    0.000000    0.000000     2.000000  \n",
       "R_longest_win_streak            1.000000    2.000000    4.000000    16.000000  \n",
       "R_losses                        1.000000    2.000000    3.000000    18.000000  \n",
       "R_total_rounds_fought           4.000000   11.000000   23.000000   448.000000  \n",
       "R_total_title_bouts             0.000000    0.000000    0.000000    16.000000  \n",
       "R_win_by_Decision_Majority      0.000000    0.000000    0.000000     2.000000  \n",
       "R_win_by_Decision_Split         0.000000    0.000000    1.000000     5.000000  \n",
       "R_win_by_Decision_Unanimous     0.000000    1.000000    2.000000    10.000000  \n",
       "R_win_by_KO/TKO                 0.000000    1.000000    2.000000    21.000000  \n",
       "R_win_by_Submission             0.000000    0.000000    1.000000    14.000000  \n",
       "R_win_by_TKO_Doctor_Stoppage    0.000000    0.000000    0.000000     2.000000  \n",
       "R_wins                          1.000000    3.000000    7.000000    33.000000  \n",
       "R_Height_cms                  172.720000  177.800000  185.420000   210.820000  \n",
       "R_Reach_cms                   175.260000  182.880000  190.500000   214.630000  \n",
       "R_Weight_lbs                  145.000000  155.000000  185.000000   265.000000  \n",
       "R_age                          27.000000   30.000000   33.000000    47.000000  \n",
       "B_age                          27.000000   29.000000   32.000000    47.000000  \n",
       "lose_streak_dif                 0.000000    0.000000    0.000000     6.000000  \n",
       "win_streak_dif                 -1.000000    0.000000    0.000000     9.000000  \n",
       "longest_win_streak_dif         -2.000000   -1.000000    0.000000    14.000000  \n",
       "win_dif                        -3.000000   -1.000000    0.000000    23.000000  \n",
       "loss_dif                       -1.000000    0.000000    2.000000    16.000000  \n",
       "total_round_dif               -12.000000   -3.000000    2.000000    80.000000  \n",
       "total_title_bout_dif            0.000000    0.000000    0.000000    14.000000  \n",
       "ko_dif                         -1.000000    0.000000    0.000000    14.000000  \n",
       "sub_dif                        -1.000000    0.000000    0.000000    10.000000  \n",
       "height_dif                     -5.080000    0.000000    5.080000    30.480000  \n",
       "reach_dif                      -5.080000    0.000000    5.080000    30.480000  \n",
       "age_dif                        -3.000000    0.000000    4.000000    17.000000  \n",
       "sig_str_dif                   -14.400000   -0.680000    5.000000   128.222222  \n",
       "avg_sub_att_dif                -0.442857    0.000000    0.233333     6.000000  \n",
       "avg_td_dif                     -1.000000    0.000000    0.590000    10.860000  \n",
       "empty_arena                     0.000000    0.000000    0.000000     1.000000  \n",
       "constant_1                      1.000000    1.000000    1.000000     1.000000  \n",
       "Winner_Categorized              0.000000    1.000000    1.000000     1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class for him is Winner_Categorized for us\n",
    "train_stats = train_df.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3369, 59)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df.pop('Winner_Categorized')\n",
    "Y_validation = validation_df.pop('Winner_Categorized')\n",
    "Y_test = test_df.pop('Winner_Categorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_stats.transpose()\n",
    "train_stats = train_stats.drop(columns = ['Winner_Categorized'])\n",
    "train_stats = train_stats.transpose()\n",
    "\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normalized_train_df = norm(train_df)\n",
    "normalized_test_df = norm(test_df)\n",
    "normalized_validation_df = norm(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation/Test Features\n",
      "Train:  (3369, 58)\n",
      "Validation:  (722, 58)\n",
      "Test:  (722, 58)\n",
      "\n",
      "Train/Validation/Test Labels\n",
      "Train:  (3369,)\n",
      "Validation:  (722,)\n",
      "Test:  (722,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train/Validation/Test Features\")\n",
    "print(\"Train: \", normalized_train_df.shape)\n",
    "print(\"Validation: \", normalized_validation_df.shape)\n",
    "print(\"Test: \", normalized_test_df.shape)\n",
    "\n",
    "print(\"\\nTrain/Validation/Test Labels\")\n",
    "print(\"Train: \", Y_train.shape)\n",
    "print(\"Validation: \", Y_validation.shape)\n",
    "print(\"Test: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NN_model(model_optimizer, model_loss, first_HL_node_count, second_HL_node_count = 4, second_HL = False):\n",
    "\n",
    "    #This is the Keras Model \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape = (normalized_train_df.shape[1],)))\n",
    "    model.add(Dense(first_HL_node_count, Activation('relu')))\n",
    "    if second_HL:\n",
    "        model.add(Dense(second_HL_node_count, Activation('relu')))\n",
    "\n",
    "    model.add(Dense(1, input_shape = (1,), activation = 'sigmoid')) \n",
    "\n",
    "    model.compile(\n",
    "        optimizer = model_optimizer,\n",
    "        loss = model_loss,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 16)                944       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 961\n",
      "Trainable params: 961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55929401/how-to-specify-model-compile-for-binary-crossentropy-activation-sigmoid-and-act\n",
    "#https://neptune.ai/blog/keras-loss-functions\n",
    "model_loss = losses.BinaryCrossentropy()\n",
    "learning_rate = 0.01\n",
    "model_optimizer = optimizers.Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "first_HL_node_count = 16\n",
    "second_HL = False\n",
    "\n",
    "model = build_NN_model(model_optimizer=model_optimizer, model_loss=model_loss, first_HL_node_count=first_HL_node_count, second_HL=second_HL)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "batch_sz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.4106 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4148 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4169 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.3955 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4029 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4169 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4163 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4026 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.3995 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4111 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4109 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4026 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4111 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4231 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.3986 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4041 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4032 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4166 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4106 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4041 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4136 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4139 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4032 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4007 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4166 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.3989 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4145 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4013 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4166 - val_loss: nan - val_accuracy: 0.4377\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        normalized_train_df,\n",
    "        Y_train,\n",
    "        batch_size = batch_sz,\n",
    "        epochs = EPOCHS,\n",
    "        verbose = 1,\n",
    "        shuffle = True,\n",
    "        steps_per_epoch = int(normalized_train_df.shape[0] / batch_sz),\n",
    "        validation_data = (normalized_validation_df, Y_validation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of results after each epoch:\n",
      "    loss  accuracy  val_loss  val_accuracy  epoch\n",
      "0    NaN  0.410606       NaN      0.437673      0\n",
      "1    NaN  0.407770       NaN      0.437673      1\n",
      "2    NaN  0.408994       NaN      0.437673      2\n",
      "3    NaN  0.410523       NaN      0.437673      3\n",
      "4    NaN  0.408994       NaN      0.437673      4\n",
      "..   ...       ...       ...           ...    ...\n",
      "95   NaN  0.410829       NaN      0.437673     95\n",
      "96   NaN  0.407158       NaN      0.437673     96\n",
      "97   NaN  0.416029       NaN      0.437673     97\n",
      "98   NaN  0.401346       NaN      0.437673     98\n",
      "99   NaN  0.416641       NaN      0.437673     99\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Summary of results after each epoch:')\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split:\n",
      "106/106 [==============================] - 1s 10ms/step - loss: nan - accuracy: 0.4099\n",
      "Accuracy:  0.41\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Split:\")\n",
    "loss, accuracy = model.evaluate(normalized_train_df, Y_train, verbose = 1)\n",
    "\n",
    "print(\"Accuracy: {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Split:\n",
      "23/23 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4377\n",
      "Accuracy:  0.44\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Split:\")\n",
    "loss, accuracy = model.evaluate(normalized_validation_df, Y_validation, verbose = 1)\n",
    "\n",
    "print(\"Accuracy: {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Split:\n",
      "23/23 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4238\n",
      "Accuracy:  0.42\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Split:\")\n",
    "loss, accuracy = model.evaluate(normalized_test_df, Y_test, verbose = 1)\n",
    "\n",
    "print(\"Accuracy: {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Positive'), Text(0, 1.5, 'Negative')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot()\n",
    "predict_results = model.predict(normalized_test_df)\n",
    "\n",
    "predict_results = (predict_results > 0.5)\n",
    "\n",
    "cm = confusion_matrix(Y_test, predict_results)\n",
    "\n",
    "sns.heatmap(cm, annot = True, ax = ax)\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Positive', 'Negative'])\n",
    "ax.yaxis.set_ticklabels(['Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NN2_model(model_optimizer, model_loss):\n",
    "\n",
    "    #This is the Keras Model \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape = (normalized_train_df.shape[1],)))\n",
    "    model.add(Dense(32, Activation('relu')))\n",
    "    model.add(Dense(24, Activation('relu')))\n",
    "    model.add(Dense(16, Activation('relu')))\n",
    "    model.add(Dense(8, Activation('relu')))\n",
    "    model.add(Dense(1, input_shape = (1,), activation = 'sigmoid')) \n",
    "\n",
    "    model.compile(\n",
    "        optimizer = model_optimizer,\n",
    "        loss = model_loss,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 32)                1888      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                400       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,225\n",
      "Trainable params: 3,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55929401/how-to-specify-model-compile-for-binary-crossentropy-activation-sigmoid-and-act\n",
    "#https://neptune.ai/blog/keras-loss-functions\n",
    "model_loss = losses.BinaryCrossentropy()\n",
    "learning_rate = 0.01\n",
    "model_optimizer = optimizers.Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "model = build_NN2_model(model_optimizer=model_optimizer, model_loss=model_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 4s 44ms/step - loss: nan - accuracy: 0.4106 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4062 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4059 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4099 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4173 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4050 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "batch_sz = 100\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        normalized_train_df,\n",
    "        Y_train,\n",
    "        batch_size = batch_sz,\n",
    "        epochs = EPOCHS,\n",
    "        verbose = 1,\n",
    "        shuffle = True,\n",
    "        steps_per_epoch = int(normalized_train_df.shape[0] / batch_sz),\n",
    "        validation_data = (normalized_validation_df, Y_validation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=p3CcfIjycBA&t=61s\n",
    "def build_NN3_model():\n",
    "\n",
    "    #This is the Keras Model \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_dim = len(normalized_train_df.columns), activation = 'relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    #model.add(Dense(32, Activation('relu')))\n",
    "    #model.add(Dense(24, Activation('relu')))\n",
    "    #model.add(Dense(16, Activation('relu')))\n",
    "    #model.add(Dense(8, Activation('relu')))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 32)                1888      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,921\n",
      "Trainable params: 1,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55929401/how-to-specify-model-compile-for-binary-crossentropy-activation-sigmoid-and-act\n",
    "#https://neptune.ai/blog/keras-loss-functions\n",
    "\n",
    "\n",
    "model = build_NN3_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 3s 40ms/step - loss: nan - accuracy: 0.4115 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4062 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4099 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4148 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.4099 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4111 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4026 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4185 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.4062 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3928 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4179 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4182 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4017 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4109 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4136 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4013 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4029 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4026 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4191 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4169 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4139 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4050 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4136 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4050 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4059 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4115 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4148 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4010 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4179 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4032 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4206 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4053 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4111 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "batch_sz = 100\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        normalized_train_df,\n",
    "        Y_train,\n",
    "        batch_size = batch_sz,\n",
    "        epochs = EPOCHS,\n",
    "        verbose = 1,\n",
    "        shuffle = True,\n",
    "        steps_per_epoch = int(normalized_train_df.shape[0] / batch_sz),\n",
    "        validation_data = (normalized_validation_df, Y_validation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=p3CcfIjycBA&t=61s\n",
    "def build_NN4_model():\n",
    "\n",
    "    #This is the Keras Model \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, input_dim = len(normalized_train_df.columns), activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1)) \n",
    "    model.add(Activation('sigmoid'))  \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 128)               7552      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 4)                 0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,593\n",
      "Trainable params: 18,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55929401/how-to-specify-model-compile-for-binary-crossentropy-activation-sigmoid-and-act\n",
    "#https://neptune.ai/blog/keras-loss-functions\n",
    "\n",
    "\n",
    "model = build_NN4_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 5s 51ms/step - loss: nan - accuracy: 0.4100 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 1s 24ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 1s 20ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 1s 19ms/step - loss: nan - accuracy: 0.4007 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4179 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4062 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.4154 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4050 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4188 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4062 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4111 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4145 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4136 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4100 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4133 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4133 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4032 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4139 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4215 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4185 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4163 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4023 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4179 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4007 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4160 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4065 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4145 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4053 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4106 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4059 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4090 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4176 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4065 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4065 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4108 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4017 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4179 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4111 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4026 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.3998 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4124 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4130 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.3983 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4032 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4163 - val_loss: nan - val_accuracy: 0.4377\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "batch_sz = 100\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        normalized_train_df,\n",
    "        Y_train,\n",
    "        batch_size = batch_sz,\n",
    "        epochs = EPOCHS,\n",
    "        verbose = 1,\n",
    "        shuffle = True,\n",
    "        steps_per_epoch = int(normalized_train_df.shape[0] / batch_sz),\n",
    "        validation_data = (normalized_validation_df, Y_validation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=WakvH7oMvPw\n",
    "#have/had no clue what was going on, what could be the problem to the model\n",
    "#no where to even think about trying to get to solve this problem\n",
    "#Watched vid and says that regression problems are hard to get working\n",
    "#because the nature of the problem leaves you prone to exploding gradients dilemma\n",
    "#Says logistic regression problems are prone to exploding gradients problem\n",
    "#generally, im thinking that if you send the neural network as much info as possible, then it will work better\n",
    "#just throwing the NN as much info as possible jumbled up and just expecting it to be solved will not ever work, even in this situation\n",
    "def build_NN5_model():\n",
    "\n",
    "    #This is the Keras Model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape = (normalized_train_df.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    sgd = optimizers.SGD(learning_rate = 0.01, nesterov = True)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'mean_absolute_error',\n",
    "        optimizer = sgd,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 128)               7552      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 4)                 0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,593\n",
      "Trainable params: 18,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55929401/how-to-specify-model-compile-for-binary-crossentropy-activation-sigmoid-and-act\n",
    "#https://neptune.ai/blog/keras-loss-functions\n",
    "\n",
    "\n",
    "model = build_NN4_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 4s 36ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 1s 19ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 1s 19ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 1s 19ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4154 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4145 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.4059 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4154 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4114 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4010 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4182 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4200 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4065 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4136 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.4145 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4062 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4099 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4088 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4093 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4099 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4041 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4069 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4056 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4145 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4154 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4072 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4078 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4154 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.3955 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4200 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4044 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4127 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.3992 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4163 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4047 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4096 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4087 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4081 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4133 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4091 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4065 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4099 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4041 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4169 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4139 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.4013 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4032 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4151 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4182 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.3958 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4139 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4105 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4133 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4075 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4102 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4191 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4026 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4084 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4117 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4142 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4035 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4173 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4038 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4157 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.3986 - val_loss: nan - val_accuracy: 0.4377\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.4121 - val_loss: nan - val_accuracy: 0.4377\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "batch_sz = 100\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        normalized_train_df,\n",
    "        Y_train,\n",
    "        batch_size = batch_sz,\n",
    "        epochs = EPOCHS,\n",
    "        verbose = 1,\n",
    "        shuffle = True,\n",
    "        steps_per_epoch = int(normalized_train_df.shape[0] / batch_sz),\n",
    "        validation_data = (normalized_validation_df, Y_validation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = pd.DataFrame(UFC_Data, columns = [\"age_dif\", \"win_streak_dif\", \"avg_td_dif\", \"Winner_Categorized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape:  (3369, 4)\n",
      "Validation Dataset Shape:  (722, 4)\n",
      "Test Dataset Shape:  (722, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df_7, test_df_7 = train_test_split(df_7, test_size = 0.3)\n",
    "test_df_7, validation_df_7 = train_test_split(test_df_7, test_size = 0.5)\n",
    "print(\"Training Dataset Shape: \", train_df_7.shape)\n",
    "print(\"Validation Dataset Shape: \", validation_df_7.shape)\n",
    "print(\"Test Dataset Shape: \", test_df_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_7 = train_df_7.pop('Winner_Categorized')\n",
    "Y_validation_7 = validation_df_7.pop('Winner_Categorized')\n",
    "Y_test_7 = test_df_7.pop('Winner_Categorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for him is Winner_Categorized for us\n",
    "train_stats_7 = train_df_7.describe()\n",
    "#train_stats_7 = train_stats_7.drop(columns = ['Winner_Categorized'])\n",
    "train_stats_7 = train_stats_7.transpose()\n",
    "\n",
    "def norm_7(x):\n",
    "    return (x - train_stats_7['mean']) / train_stats_7['std']\n",
    "\n",
    "normalized_train_df_7 = norm_7(train_df_7)\n",
    "normalized_test_df_7 = norm_7(test_df_7)\n",
    "normalized_validation_df_7 = norm_7(validation_df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation/Test Features (DataFrame 7)\n",
      "Train:  (3369, 3)\n",
      "Validation:  (722, 3)\n",
      "Test:  (722, 3)\n",
      "\n",
      "Train/Validation/Test Labels (DataFrame 7)\n",
      "Train:  (3369,)\n",
      "Validation:  (722,)\n",
      "Test:  (722,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train/Validation/Test Features (DataFrame 7)\")\n",
    "print(\"Train: \", normalized_train_df_7.shape)\n",
    "print(\"Validation: \", normalized_validation_df_7.shape)\n",
    "print(\"Test: \", normalized_test_df_7.shape)\n",
    "\n",
    "print(\"\\nTrain/Validation/Test Labels (DataFrame 7)\")\n",
    "print(\"Train: \", Y_train_7.shape)\n",
    "print(\"Validation: \", Y_validation_7.shape)\n",
    "print(\"Test: \", Y_test_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NN5_model():\n",
    "\n",
    "    #This is the Keras Model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape = (normalized_train_df_7.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    sgd = optimizers.SGD(learning_rate = 0.01, nesterov = True)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'mean_absolute_error',\n",
    "        optimizer = sgd,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_53 (Dense)            (None, 1024)              4096      \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660,481\n",
      "Trainable params: 660,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55929401/how-to-specify-model-compile-for-binary-crossentropy-activation-sigmoid-and-act\n",
    "#https://neptune.ai/blog/keras-loss-functions\n",
    "\n",
    "\n",
    "model = build_NN5_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 2s 33ms/step - loss: 0.5656 - accuracy: 0.4118 - val_loss: 0.5342 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.5198 - accuracy: 0.4423 - val_loss: 0.4891 - val_accuracy: 0.5194\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.4808 - accuracy: 0.5519 - val_loss: 0.4619 - val_accuracy: 0.5789\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.4631 - accuracy: 0.5730 - val_loss: 0.4569 - val_accuracy: 0.5845\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.4508 - accuracy: 0.5892 - val_loss: 0.4522 - val_accuracy: 0.5845\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.5876 - val_loss: 0.4455 - val_accuracy: 0.5845\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4416 - accuracy: 0.5861 - val_loss: 0.4372 - val_accuracy: 0.5845\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4290 - accuracy: 0.5941 - val_loss: 0.4312 - val_accuracy: 0.5845\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4304 - accuracy: 0.5855 - val_loss: 0.4268 - val_accuracy: 0.5859\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.4255 - accuracy: 0.5892 - val_loss: 0.4213 - val_accuracy: 0.5886\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.5965 - val_loss: 0.4183 - val_accuracy: 0.5914\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.4263 - accuracy: 0.5870 - val_loss: 0.4176 - val_accuracy: 0.5886\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4148 - accuracy: 0.5974 - val_loss: 0.4161 - val_accuracy: 0.5900\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4188 - accuracy: 0.5935 - val_loss: 0.4167 - val_accuracy: 0.5873\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4258 - accuracy: 0.5919 - val_loss: 0.4161 - val_accuracy: 0.5914\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4135 - accuracy: 0.6066 - val_loss: 0.4142 - val_accuracy: 0.5970\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.6035 - val_loss: 0.4138 - val_accuracy: 0.5970\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 0.5889 - val_loss: 0.4146 - val_accuracy: 0.5983\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4082 - accuracy: 0.6097 - val_loss: 0.4130 - val_accuracy: 0.5983\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4151 - accuracy: 0.6017 - val_loss: 0.4142 - val_accuracy: 0.6011\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4173 - accuracy: 0.6048 - val_loss: 0.4126 - val_accuracy: 0.5997\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4104 - accuracy: 0.6081 - val_loss: 0.4135 - val_accuracy: 0.6039\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4128 - accuracy: 0.5968 - val_loss: 0.4133 - val_accuracy: 0.6011\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.6023 - val_loss: 0.4121 - val_accuracy: 0.6039\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4121 - accuracy: 0.6057 - val_loss: 0.4131 - val_accuracy: 0.5983\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4061 - accuracy: 0.6115 - val_loss: 0.4122 - val_accuracy: 0.6011\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4207 - accuracy: 0.5938 - val_loss: 0.4121 - val_accuracy: 0.5997\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4116 - accuracy: 0.6060 - val_loss: 0.4114 - val_accuracy: 0.5983\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.6081 - val_loss: 0.4123 - val_accuracy: 0.6011\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4106 - accuracy: 0.6035 - val_loss: 0.4119 - val_accuracy: 0.5983\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4102 - accuracy: 0.6087 - val_loss: 0.4112 - val_accuracy: 0.6025\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.6048 - val_loss: 0.4111 - val_accuracy: 0.6011\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4138 - accuracy: 0.6042 - val_loss: 0.4134 - val_accuracy: 0.6011\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.6060 - val_loss: 0.4111 - val_accuracy: 0.6011\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4103 - accuracy: 0.6079 - val_loss: 0.4121 - val_accuracy: 0.6011\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4123 - accuracy: 0.6060 - val_loss: 0.4119 - val_accuracy: 0.6011\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4132 - accuracy: 0.5990 - val_loss: 0.4123 - val_accuracy: 0.6011\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4051 - accuracy: 0.6127 - val_loss: 0.4113 - val_accuracy: 0.5997\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4163 - accuracy: 0.6072 - val_loss: 0.4116 - val_accuracy: 0.5983\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.6048 - val_loss: 0.4109 - val_accuracy: 0.6039\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4049 - accuracy: 0.6143 - val_loss: 0.4116 - val_accuracy: 0.5983\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4113 - accuracy: 0.6081 - val_loss: 0.4119 - val_accuracy: 0.5983\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.6097 - val_loss: 0.4112 - val_accuracy: 0.5970\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4082 - accuracy: 0.6091 - val_loss: 0.4104 - val_accuracy: 0.5997\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.6066 - val_loss: 0.4105 - val_accuracy: 0.6011\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4166 - accuracy: 0.5983 - val_loss: 0.4112 - val_accuracy: 0.6011\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4053 - accuracy: 0.6167 - val_loss: 0.4109 - val_accuracy: 0.6011\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4050 - accuracy: 0.6106 - val_loss: 0.4113 - val_accuracy: 0.5956\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4158 - accuracy: 0.5977 - val_loss: 0.4105 - val_accuracy: 0.5997\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4086 - accuracy: 0.6106 - val_loss: 0.4109 - val_accuracy: 0.5997\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.6084 - val_loss: 0.4106 - val_accuracy: 0.5983\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4082 - accuracy: 0.6066 - val_loss: 0.4114 - val_accuracy: 0.5983\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4068 - accuracy: 0.6072 - val_loss: 0.4107 - val_accuracy: 0.6011\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4091 - accuracy: 0.6078 - val_loss: 0.4116 - val_accuracy: 0.5997\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.6060 - val_loss: 0.4104 - val_accuracy: 0.5983\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4106 - accuracy: 0.6054 - val_loss: 0.4104 - val_accuracy: 0.5983\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4096 - accuracy: 0.6069 - val_loss: 0.4114 - val_accuracy: 0.5983\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4038 - accuracy: 0.6115 - val_loss: 0.4105 - val_accuracy: 0.5997\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4126 - accuracy: 0.6057 - val_loss: 0.4110 - val_accuracy: 0.5970\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4087 - accuracy: 0.6066 - val_loss: 0.4130 - val_accuracy: 0.5928\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3987 - accuracy: 0.6182 - val_loss: 0.4105 - val_accuracy: 0.6011\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4144 - accuracy: 0.5971 - val_loss: 0.4108 - val_accuracy: 0.5956\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.6091 - val_loss: 0.4105 - val_accuracy: 0.5942\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4092 - accuracy: 0.6072 - val_loss: 0.4103 - val_accuracy: 0.5970\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4065 - accuracy: 0.6081 - val_loss: 0.4101 - val_accuracy: 0.5983\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.4130 - accuracy: 0.6011 - val_loss: 0.4108 - val_accuracy: 0.5983\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.6072 - val_loss: 0.4103 - val_accuracy: 0.5983\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4066 - accuracy: 0.6087 - val_loss: 0.4103 - val_accuracy: 0.5983\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4080 - accuracy: 0.6073 - val_loss: 0.4107 - val_accuracy: 0.5970\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4079 - accuracy: 0.6087 - val_loss: 0.4107 - val_accuracy: 0.5983\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4088 - accuracy: 0.6091 - val_loss: 0.4100 - val_accuracy: 0.5983\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4090 - accuracy: 0.6054 - val_loss: 0.4106 - val_accuracy: 0.5970\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4093 - accuracy: 0.6091 - val_loss: 0.4101 - val_accuracy: 0.5970\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4050 - accuracy: 0.6063 - val_loss: 0.4101 - val_accuracy: 0.5970\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4068 - accuracy: 0.6051 - val_loss: 0.4098 - val_accuracy: 0.5983\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4080 - accuracy: 0.6091 - val_loss: 0.4107 - val_accuracy: 0.5970\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4103 - accuracy: 0.6011 - val_loss: 0.4103 - val_accuracy: 0.5970\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4034 - accuracy: 0.6130 - val_loss: 0.4104 - val_accuracy: 0.5956\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.4102 - accuracy: 0.5974 - val_loss: 0.4101 - val_accuracy: 0.5956\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4088 - accuracy: 0.6072 - val_loss: 0.4112 - val_accuracy: 0.5983\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4063 - accuracy: 0.6054 - val_loss: 0.4116 - val_accuracy: 0.5970\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4119 - accuracy: 0.6054 - val_loss: 0.4113 - val_accuracy: 0.5970\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3998 - accuracy: 0.6121 - val_loss: 0.4114 - val_accuracy: 0.5970\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.6152 - val_loss: 0.4100 - val_accuracy: 0.5970\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.5907 - val_loss: 0.4118 - val_accuracy: 0.5970\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4013 - accuracy: 0.6149 - val_loss: 0.4101 - val_accuracy: 0.5983\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4071 - accuracy: 0.6075 - val_loss: 0.4108 - val_accuracy: 0.5970\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4116 - accuracy: 0.6042 - val_loss: 0.4110 - val_accuracy: 0.5970\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4013 - accuracy: 0.6115 - val_loss: 0.4105 - val_accuracy: 0.5970\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.6103 - val_loss: 0.4101 - val_accuracy: 0.5970\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4065 - accuracy: 0.6075 - val_loss: 0.4114 - val_accuracy: 0.5970\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4078 - accuracy: 0.6060 - val_loss: 0.4119 - val_accuracy: 0.5970\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4070 - accuracy: 0.6094 - val_loss: 0.4105 - val_accuracy: 0.5970\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4040 - accuracy: 0.6075 - val_loss: 0.4115 - val_accuracy: 0.5983\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4032 - accuracy: 0.6115 - val_loss: 0.4109 - val_accuracy: 0.5970\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4094 - accuracy: 0.6060 - val_loss: 0.4114 - val_accuracy: 0.5956\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4101 - accuracy: 0.6020 - val_loss: 0.4114 - val_accuracy: 0.5970\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4062 - accuracy: 0.6109 - val_loss: 0.4112 - val_accuracy: 0.5983\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4002 - accuracy: 0.6143 - val_loss: 0.4102 - val_accuracy: 0.5970\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4101 - accuracy: 0.6032 - val_loss: 0.4108 - val_accuracy: 0.5983\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "batch_sz = 100\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        normalized_train_df_7,\n",
    "        Y_train_7,\n",
    "        batch_size = batch_sz,\n",
    "        epochs = EPOCHS,\n",
    "        verbose = 1,\n",
    "        shuffle = True,\n",
    "        steps_per_epoch = int(normalized_train_df_7.shape[0] / batch_sz),\n",
    "        validation_data = (normalized_validation_df_7, Y_validation_7),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdd6fe30c950e95df9896ea7b0082cb09a67998b306e267934b2648cee2217bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('UFCNN': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
